\newcommand\notmember[2]{\neg \ebox{\mem \<\ebox{#1} \<{#2}}}
\renewcommand\notmember[2]{\ebox{#1} \not \in \ebox{#2}}

\section{Examples}
\label{examples}

\input{2-figure-sugar}

For brevity and clarity, the examples that follow make use of some syntax sugar:

\begin{enumerate}

\item We mentioned earlier that Datafun's boolean type \tbool\ is ordered
  $\efalse < \etrue$. This is because we encode booleans as sets of empty
  tuples, $\tset{\tunit}$, with \etrue\ as the singleton $\esetraw{\etuple{}}$
  and \efalse\ as the empty set $\esetraw{}$. In a loop over a boolean,
  $\eforvar x e f$, the variable $\dvar x$ contains no useful information; if
  for brevity we omit it, the condensed expression $\efor{e} f$ may be thought
  of as a ``one-sided'' conditional:

%  so the expression becomes a ``one-sided'' conditional, which we abbreviate $\efor{e} f$:

  \begin{equation*}
    \efor{e} f =
    \begin{cases}
      f & \text{if }e\text{ is }\etrue\\
      \bot & \text{if }e\text{ is }\efalse
    \end{cases}
  \end{equation*}

  Compared with encoding booleans as a sum type \(\tunit + \tunit\), our
  approach has the advantage that it can express the type of ``monotone''
  predicates $P \isa A \to \tbool$ such that $P(x)$ may change from $\efalse$ to
  $\etrue$ as $x$ grows, but cannot revert from $\etrue$ to $\efalse$.

%% and our
%%   one-sided conditional as \kw{case}, our approach has the advantage that
%%   $\efor{b} e$ is monotone in the condition $b$.
%% %
%%   \splittodo{technically incorrect, when would still be monotone.}{but we'd be losing information when we converted \emph{into} a boolean type from an ordered one. hm.}

  %% \splittodo{do we ever use $\kw{when}$?}{YES: intersection example. but this might go away after rewrite. anywhere else? I think we only use conditions in set comprehensions and the like.}

\item We make use of pattern matching. Besides the usual sum/tuple patterns, we
  support box-patterns $\pbox{p}$ and equality-check patterns $\peq{e}$. Box
  patterns $\pbox{p}$ correspond to box-elimination $\eletbox x e f$, and their
  effect is to make all of the variables bound by $p$ discrete. The
  equality-check pattern $\peq{e}$ matches only a value equal to $\eiso{e}$ --
  this is particularly useful when combined with set comprehensions.

\item We make use of set comprehensions, which can be desugared into the monadic
  operator \kw{for}~\citep{wadler-monad-comprehensions}. We also support
  looping/comprehending over only those elements of a set which match a certain
  pattern.

\item We permit ourselves a top-level surface syntax similar to Haskell or SML. In particular, we allow:

  \begin{enumerate}
  \item Function definitions, including currying:

    \begin{code}
      \name{disjunction} \isa \tbool \to \tbool \to \tbool\\
      \name{disjunction} \<\mvar x \<\mvar y = \mvar x \vee \mvar y
    \end{code}

  \item Type aliases:

    \XXX

  \item Algebraic datatype definitions, introduced by the syntax \kw{data}:

    \begin{code}
      \kw{data}~\typename{color} =
      \ctor{black}
      ~|~ \ctor{named} \<\typename{string}
      ~|~ \ctor{rgb} \<\typename{int} \<\typename{int} \<\typename{int}
    \end{code}

    We do not allow these types to be defined recursively, so they can be easily
    desugared into sums of products in the standard way. Similarly, we allow
    ourselves $n$-ary tuples, since they can easily be desugared into nested
    binary tuples.
  \end{enumerate}

\end{enumerate}

\noindent
We summarize the desugaring rules we use in \cref{figure-sugar}, excepting our
top-level declarations and the desugaring of algebraic data types, which should
be fairly familiar.


\subsection{Set operations and relational algebra}
\label{set-operations-and-relational-algebra}

\todo{reorder this to introduce equality patterns.}
\splittodo{introduce not-a-member function}{$\notmember{x}{s}$, it's used in dataflow examples, eg. in \name{live}}

\newcommand\mem{\name{member}}

One of the main features of Datafun is that it permits manipulating
relations as first class values.
%
In this subsection we will show how a variety of standard operations on sets can
be represented in Datafun.
%
The first operation we consider is testing membership:

\begin{code}
  \mem \isa \iso \eqt A \to \tseteq A \to \tbool\\
  \mem \<\pboxvar x \<\mvar s = \eforvar{y}{\mvar s} \eeq {\dvar x} {\dvar y}
\end{code}

\noindent
This checks if $\dvar x$ is equal to any element $\dvar y \in \mvar s$. The
argument $\dvar x$ is discrete because increasing $\dvar x$ might send it from
being \emph{in} the set to being \emph{outside} the set: although $1 \le 2$ and
$1 \in \esetraw{1}$, nonetheless $2 \notin \esetraw{1}$. Notice that here we're
taking advantage of encoding booleans as sets of empty tuples -- unioning these
sets implements logical \emph{or}.

Next we turn to set union and intersection. Union is baked into Datafun as the
semilattice join, $x \cup y = x \vee y$, while intersection is definable using
\mem, by taking the union of every singleton $\esetraw{\dvar x}$ such that
$\dvar x$ is in both $s$ and $t$:

\newcommand\compose\bullet

\begin{code}
  \pwild \cap \pwild \isa \tseteq A \to \tseteq A \to \tseteq A\\
  %% NB. \kern -.5pt to get "member" closer to open paren.
  \mvar s \cap \mvar t =
  %\eforvar x {\mvar s} \ewhen{\kern -.5pt \mem \<\eboxvar x \<\mvar t}
  \efor{\dvar x \in \mvar s,\, \mem \<\eboxvar x \<\mvar t}
%  \efor{\dvar x \in \mvar s} \efor{\pwild \in \mem \<\eboxvar x \<\mvar t}
  \eset{\dvar x}
\end{code}

\noindent
Using comprehensions, this could alternately be written as:

\begin{code}
  \mvar s \cap \mvar t =
  \esetfor{\dvar x}{\dvar x \in \mvar s,\, \mem \<\eboxvar x \<\mvar t}
\end{code}

\noindent From now on, we'll use comprehensions whenever possible. For example, comprehensions make cross product and relational composition look almost exactly like their mathematical definitions:

\begin{code}
  \pwild \x \pwild \isa \tseteq A \to \tseteq B \to \tset{\eqt A \x \eqt B}\\
  \mvar s \x \mvar t =
  \esetfor{\etuple{\dvar x, \dvar y}}{\dvar x \in \mvar s,\, \dvar y \in \mvar t}
  \\[\betweenfunctionskip]
  \pwild \compose \pwild \isa
  \tset{\eqt A \x \eqt B}
  \to \tset{\eqt B \x \eqt C}
  \to \tset{\eqt A \x \eqt C}\\
  \mvar s \compose \mvar t = \esetfor{\etuple{\dvar a, \dvar c}}{
    \ptuple{\dvar a, \bone} \in \mvar s,\,
    \ptuple{\btwo, \dvar c} \in \mvar t,\,
    \eeq \bone \btwo}
\end{code}

\noindent
The definitions of functional programming stalwarts \emph{filter} and \emph{map}
(or in relational algebra terms, \emph{select} and \emph{project}) are slightly
complicated by the need to be explicit about
(non-\nolinebreak[4])\linebreak[0]monotonicity:

\newcommand{\kernf}{\kern1.67pt f}
\newcommand{\kernfpost}{\kern.3pt}
\renewcommand{\kernf}{f}
\renewcommand{\kernfpost}{\kern.4pt}

\begin{code}
  \name{filter} \isa (\iso \eqt A \to \tbool) \to \tseteq A \to \tseteq A\\
  \name{filter} \<\mvar f \<\mvar s =
  \esetfor{\dvar x}{\dvar x \in \mvar s,\, \mvar f\<\ebox{\dvar x}}
  \\[\betweenfunctionskip]
  \name{map} \isa \iso(\iso \eqt A \to \eqt B) \to \tseteq A \to \tseteq B\\
  % need some kerning between the [{ and the f
  \name{map} \<\pboxvar{\kernf\kernfpost} \<\mvar s = \esetfor{\dvar{\kernf}\<\ebox{\dvar x}}{\dvar x \in \mvar s}
\end{code}

\noindent
Why is \name{filter} monotone in its function argument while \name{map} is not? Recall that functions are ordered pointwise while sets are ordered by inclusion, and observe that increasing the filtering function (making it \emph{true} on more inputs) enlarges the result of \name{filter}, but the same does not hold for \name{map}: 

\[\begin{array}{rcccccr}
  \name{filter} \<(\le 0) \<\esetraw{0,1}
  &=& \esetraw{0}
  &\subseteq&
  \esetraw{0,1}
  &=&
  \name{filter} \<(\le 1) \<\esetraw{0,1}
  \\
  \name{map} \<(\le 0) \<\esetraw{0,1}
  &=&
  \esetraw{\etrue,\, \efalse}
  &\not\subseteq&
  \esetraw{\etrue}
  &=& \name{map} \<(\le 1) \<\esetraw{0,1}
\end{array}\]

\noindent
\todo{explain why neither map nor filter requires function to be monotone}

We can also define set difference, although we must first detour into boolean
negation:

\todo{use discrete case? Define not member function?}
\begin{code}
  {\neg} \isa \iso\tbool \to \tbool\\
  \neg \pboxvar t = \emcase{\eisempty{\dvar t}}
  \inj 1 \ptuple{} \caseto \etrue\textsf \casebar \inj 2 \ptuple{} \caseto \efalse
  \\[\betweenfunctionskip]
  \pwild\setminus\pwild \isa \tseteq A \to \iso \tseteq A \to \tseteq A\\
  \mvar s \setminus \pboxvar t =
  \esetfor{\dvar x}{\dvar x \in \mvar s,\, \notmember{\dvar x}{\dvar t}}
\end{code}

\noindent
To implement boolean negation, we need the primitive operator $\eisempty e$,
which produces a tag indicating whether its argument $e$ (a boolean, i.e. a set
of empty tuples) is the empty set.
%
This in turn lets us define set difference, the analogue in Datafun of negation
in Datalog.
%
Note that in both boolean negation and set difference the ``negated'' argument
$\dvar t$ is boxed, because the operation is not monotone in $\dvar t$.
%
This enforces stratification.

\label{section-datafun-transitive-closure}
Finally, generalizing the \name{ancestor} relation from the Datalog program in
\cref{section-datalog}, we can define the transitive closure of a relation:

\nopagebreak[2]
\begin{code}
  \name{trans} \isa \iso \tset{\eqt A \x \eqt A} \to \tset{\eqt A \x \eqt A}\\
  \name{trans} \<\pboxvarlong{edge} =
  \efixis{R}{\dvarlong{edge} \vee (\dvarlong{edge} \compose \mvar R)}
\end{code}

\noindent
This definition uses a least fixed point, just like the mathematical definition
-- a transitive closure is the least relation $\mvar R$ including both the
original relation $\dvarlong{edge}$ and the composition of $\dvarlong{edge}$
with $\mvar R$.
%
\todo{rewrite this sentence:}
However, one feature of this definition peculiar to Datafun is that the argument
type is $\iso \tset{\eqt A \times \eqt A}$; the transitive closure takes a
\emph{discrete} relation.
%
This is because we must use the relation within the fixed point, and so its
parameter needs to be discrete to occur within.
%
This restriction is artificial -- transitive closure is semantically a monotone
operation -- but its explanation will have to wait until \todo{fwdref discreteness of fix}.


\subsection{Regular expression combinators}
\label{regex-combinators}

\newcommand\tre{\typename{regex}}
\newcommand\tchar{\typename{char}}

Datafun permits tightly integrating the higher-order functional and bottom-up
logic programming styles. To illustrate the benefits of doing so, in this
section we implement a regular expression matching library in combinator style.
Like combinator parsers in functional languages, the code is very concise.
%
However, support for the relational style ensures we can write \naive\ code
\emph{without} the exponential backtracking cliffs typical of parser combinators
in functional languages.

For these examples we'll assume the existence of eqtypes \tstring, \tchar, and
\tint, an addition operator $+$, and functions \name{length} and \name{chars}
satisfying:

\begin{code}
  \name{length} \isa \iso\tstring \to \tint\\
  \name{length} \<\pboxvar{s} = \text{the length of }\dvar s
  \\[\betweenfunctionskip]
  \name{chars} \isa \iso\tstring \to \tset{\tint \x \tchar}\\
  \name{chars} \<\pboxvar{s} =
  \setfor{(i,c)}{\text{the $i$\textsuperscript{th}
      character of $\dvar s$ is $c$}}
\end{code}

\noindent
Note that by always boxing string arguments, we avoid committing ourselves to
any particular partial ordering on \tstring.

These assumed, we define the type of regular expression matchers:

\begin{code}
\kw{type}\ \tre = \iso \tstring \to \tset{\tint \times \tint}
\end{code}

\noindent
A regular expression takes a discrete string $\pboxvar s$ and returns the set of
all pairs $(i,j)$ such that the substring $\dvar s_i,\, \ldots,\, \dvar s_{j-1}$
matches the regular expression. For example, to find all matches for a single
character $c$, we return the range $(i,i+1)$ whenever $(i,c) \in
\name{chars}\<\eboxvar s$:

\begin{code}
  \name{sym} \isa \iso\tchar \to \tre\\
  \name{sym} \<\pboxvar c \<\pboxvar s =
  \esetfor{(\dvar i, \dvar i + 1)}{
    \ptuple{\dvar i, \peqvar c} \in \name{chars} \<\eboxvar s}
\end{code}

\noindent
To find all matches for the empty regex, i.e.\ all empty substrings, including
the one ``beyond the last character'':

\begin{code}
  \name{nil} \isa \tre\\
  \name{nil} \<\pboxvar s =
  \esetfor{\dvar i}{\ptuple{\dvar i, \pwild} \in \name{chars}\<\eboxvar s}
  \vee \eset{\name{length}\<\eboxvar s}
\end{code}

\noindent
Appending regexes $\mvar r_1, \mvar r_2$ amounts to relation composition, since
we wish to find all substrings consisting of adjacent substrings $s_i \ldots
s_{j-1}$ and $s_j \ldots s_{k-1}$ matching $\mvar r_1$ and $\mvar r_2$
respectively:

\nopagebreak[2]
\begin{code}
  \name{seq} \isa \tre \to \tre \to \tre\\
  \name{seq} \<\mvar r_1 \<\mvar r_2 \<\mvar s = \mvar r_1 \<\mvar s \compose \mvar r_2 \<\mvar s
\end{code}

\noindent
Similarly, regex alternation \texttt{r\textsubscript{1}|r\textsubscript{2}} is
accomplished by unioning all matches of each:

\nopagebreak[2]
\begin{code}
  \name{alt} \isa \tre \to \tre \to \tre\\
  \name{alt} \<\mvar r_1 \<\mvar r_2  \<\mvar s = \mvar r_1 \<\mvar s \vee \mvar r_2 \<\mvar s
\end{code}

\noindent
The most interesting regular expression combinator is Kleene star. Thinking
relationally, if we consider the set of pairs $(i,j)$ matching some regex
\texttt{r}, then \texttt{r*} matches its \emph{reflexive, transitive closure}.
This can be accomplished by combining \emph{nil} and \emph{trans}.

\nopagebreak[2]
\begin{code}
  \name{star} \isa \iso\tre \to \tre\\
  \name{star} \<\pboxvar r \<\pboxvar s =
  \name{nil}\<\eboxvar s \vee
  \name{trans} \<\ebox{\dvar r \<\eboxvar s}
\end{code}

\noindent
Note that the argument $\dvar r$ must be discrete because \name{trans} uses it
to compute a fixed point.\footnote{Technically the inclusion order on sets of
  integer pairs does not satisfy the ascending chain condition, so this use
  of \name{trans} is not well-typed. However, since the positions in a
  particular string form a finite set, semantically there is no issue.
  We will address this in \cref{section-nested-fixed-points}.}



\subsection{Regular expression combinators, take two}
\label{regex-combinators-take-two}

\newcommand\kernj{\kern1pt j}
\renewcommand\kernj{j}

%% TODO: edit/rewrite this section, especially the bit about left recursion, it
%% needs to be clearer

The combinators in the previous section found \emph{all} matches
within a given substring, but often we are not interested in all
matches: we only want to know if a string can match starting at a
particular location. We can easily refactor the combinators above to
work in this style, which illustrates the benefits of tightly
integrating functional and relational styles of programming -- we can
use functions to manage strict input/output divisions, and relations
to manage nondeterminism and search.

\begin{code}
  \kw{type}\ \tre = \iso (\tstring \x \tint) \to \tset{\tint}
\end{code}

\noindent
Our new type of combinators takes a string and a starting position, and returns
a set of ending positions. For example, $\name{sym} \<\eboxvar c$ checks if
$\dvar c$ occurs at the start position $\dvar i$, yielding $\esetraw{\dvar i+1}$
if it does and the empty set otherwise, while \name{nil} simply returns the
start position $\dvar i$.

\nopagebreak[2]
\begin{code}
  \name{sym} \isa \iso\tchar \to \tre\\
  \name{sym} \<\pboxvar{c} \<\pboxtuple{\dvar{s}, \dvar{i}}
  = \esetfor{\dvar i+1}{
    \peq{\etuple{\dvar{i}, \dvar c}} \in \name{chars} \<\eboxvar{s}
    %\mem \<\eboxtuple{\dvar i, \dvar c} \<\name{chars}
  }
  \\[\betweenfunctionskip]
  \name{nil} \isa \tre \to \tre\\
  \name{nil} \<\pboxtuple{\dvar{s}, \dvar{i}} = \eset{\dvar{i}}
\end{code}

\noindent
Appending regexes $\name{seq}\<\mvar r_1\<\mvar r_2$ simply applies $\mvar r_2$ starting from
every ending position that $\mvar r_1$ can find:

\nopagebreak[2]
\begin{code}
  \name{seq} \isa \tre \to \tre \to \tre\\
  \name{seq} \<\mvar r_1 \<\mvar r_2 \<\pboxtuple{\dvar{s}, \dvar{i}} =
  \eforvar{\kernj}{\mvar r_1\<\eboxtuple{\dvar{s}, \dvar{i}}}
  \mvar r_2 \<\eboxtuple{\dvar{s}, \dvar j}
\end{code}

\noindent
Regex alternation \name{alt} is effectively unchanged:

\nopagebreak[2]
\begin{code}
  \name{alt} \isa \tre \to \tre \to \tre\\
  \name{alt} \<\mvar r_1 \<\mvar r_2 \<\mvar x = \mvar r_1\<\mvar x \vee \mvar r_2\<\mvar x
\end{code}

\noindent
Finally, Kleene star is implemented by recursively appending $\dvar r$ to a
set $\mvar x$ of matches found so far:

\nopagebreak[2]
\begin{code}
  \name{star} \isa \iso\tre \to \tre\\
  \name{star} \<\pboxvar r \<\pboxtuple{\dvar{s}, \dvar{i}}
  = \efixis{x}{\bigl(\eset{\dvar{i}} \vee
    \eforvar {\kernj} {\mvar x} \dvar r\<\eboxtuple{\dvar{s}, \dvar j}
    \bigr)}
\end{code}

\noindent
It's worth noting that this definition is effectively \emph{left-recursive} --
it takes the endpoints from the fixed point $x$, and then continues matching
using the argument $\dvar r$. This should make clear that this is not just plain
old functional programming -- we are genuinely relying upon the fixed point
semantics of Datafun.


\subsection{CYK parsing}
\label{cyk-parsing}

Parsing can be understood logically: a parse tree is a proof that a string
belongs to a language, and parsing is proof search~\citep{deductive-parsing}.
%
One of the simplest parsing algorithms is the Cocke-Younger-Kasami (CYK)
algorithm for parsing grammars in Chomsky normal form; that is, where each
production is either of the form $A \to B\,C$ or $A \to \vec{a}$, with $A,B,C$
ranging over nonterminals and $\vec{a}$ over strings of terminals.
%
Fix a Chomsky-normal grammar $G$ and a word $w = w_0 w_1 ... w_{n-1}$ to be parsed,
and write $w_{i..j}$ for the substring $w_i ... w_{j-1}$.
%
Now, we introduce a family of predicates $A(i,j)$ (sometimes called
\emph{facts}), intended to represent the proposition that $w_{i..j}$ is
generated by the nonterminal $A$.
%
Then, we can specify the CYK algorithm with the following two inference rules:
%
\todo{too much space before this mathpar}

\begin{mathpar}
  \inferrule*{(A \to B\,C) \in G \\ B(i, j) \\ C(j, k)}
             {A(i, k)}
  \and
  \inferrule*{(A \to \vec{a}) \in G \\ \vec{a} = w_{i..j}}
             {A(i,j)}
\end{mathpar}

\noindent
\todo{explain CYK rules.} Then the whole word $w$ is generated by the start
symbol $S$ if $S(0,n)$ is derivable.

In Datafun, this rule-based description of the algorithm can be transliterated
almost directly into code. We begin by introducing a few basic types.

\newcommand\tfact{\typename{fact}}
\newcommand\tsymbol{\typename{symbol}}
\newcommand\tgrammar{\typename{grammar}}

\begin{code}
\kw{type}~\tsymbol = \tstring\\
\kw{data}~\typename{rule}
= \ctor{String} \<\tstring
~|~ \ctor{Concat} \<\tsymbol \<\tsymbol\\
\kw{type}~\tgrammar = \tset{\tsymbol \x \typename{rule}}\\
\kw{type}~\tfact = \tsymbol \x \tint \x \tint\\
\end{code}

\noindent
The $\tsymbol$ type is a type synonym representing nonterminal names
with strings. The $\typename{rule}$ type is the type of the right-hand-sides
of productions in Chomsky normal form -- either a string, or a pair of
nonterminals. A $\tgrammar$ is just a set of productions -- a set
of pairs of nonterminals paired with their rules. The type $\tfact$
is the type representing the atomic facts derived by the CYK inference
system -- they are triples of the rulename, the start position, and
the end position.

\todo{explain helper functions}

\begin{code}
  \name{length} \isa \iso\tstring \to \tint\\
  \name{range} \isa \iso \tint \to \tint \to \tset{\tint}\\
  \name{substring} \isa \iso(\tstring \x \tint \x \tint) \to \tstring\\
  (+) \isa \tint \to \tint \to \tint\\
  (-) \isa \tint \to \iso\tint \to \tint
\end{code}

\noindent
With these types in hand, we can write the CYK algorithm as a fixed point
computation. In fact, it is convenient to break it into two pieces, by first
defining the function whose fixed point we take. So we can write down the
$\name{iter}$ function, which represents one step of the fixed point iteration.

\begin{code}
  \name{iter} \isa \iso \tstring \to \iso\tgrammar
  \to \tset{\tfact} \to \tset{\tfact}\\
  \name{iter} \<\pboxvarlong{text} \<\pboxvarlong{grammar} \<\mvar f =
  \\\phantom{\quad\cup{}} \{~\eiso{\etuple{\dvar a,\, \dvar i,\, \dvar k}}
  ~|~
  (\dvar a,\, \ctor{concat} \<\dvar b \<\dvar c) \in \dvarlong{grammar},
  \etuple{\peqvar b, \dvar i, \dvar j} \in \mvar f,
  \etuple{\peqvar c, \peqvar j, \dvar k} \in \mvar f ~\}
  \\\quad\cup \{~
  \eiso{\etuple{\dvar a,\, \dvar i,\, \dvar i + \name{length}\<\dvar s}}
  \\\phantom{\quad\cup{}} |~
  (\dvar a,\, \ctor{String}\<\dvar s) \in \dvarlong{grammar},
  \\\phantom{\quad\cup{}} \phantom{|~}
  \dvar i \in \name{range} \<\ebox{0} \<(\name{length} \<\dvarlong{text} - \ebox{\name{length} \<\dvar s}),
  \\\phantom{\quad\cup{}} \phantom{|~} \dvar s =
  \name{substring} \<\ebox{\dvarlong{text},\, \dvar i,\, \dvar i + \name{length}\<\dvar s}
  ~\}
\end{code}

\noindent
We can then use $\name{iter}$ to implement the $\name{parse}$ function:

\begin{code}
  \name{parse} \isa \iso \tstring \to \iso \tgrammar \to \tset{\tsymbol}\\
  \name{parse} \>\pboxvarlong{text} \>\pboxvarlong{grammar} = \\
  \quad \esetfor{\dvar a}{%
    \etuple{\dvar a,\, \peq 0,\, \peq{(\name{length}\<\dvarlong{text})}}
    \in \efixis{x}{\name{iter} \<\ebox{\dvarlong{text}} \<\ebox{\dvarlong{grammar}} \<\mvar x}}
\end{code}

\noindent
This finds all nonterminals in \name{grammar} that generate the entire string
\name{text}. \todo{more detail: why does parse work?}

%% This function just takes the fixed point of $\name{iter}$ --
%% almost. Because facts are triples $\tsymbol \x \N \x \N$, sets of
%% facts may in general grow unboundedly.  To ensure termination, we
%% construct a set $\m{bound}$ to bound the sets of facts we consider in
%% our fixed point computation, by bounding the symbols to names found in
%% the grammar \name{grammar}, and the indices to positions of the string. Since
%% all of these are finite, we know that the computation of $\name{chart}$
%% as a bounded fixed point will terminate. Then, having computed the
%% fixed point, we can check chart to see if $(a, 0, \name{length}\;\name{text})$
%% is derivable.

This program is not expressible in Datalog, because Datalog provides no way to
\emph{abstract} over grammars. The rules of a grammar are easily represented as
Datalog relations --- but since Datalog is first-order, it cannot parameterize
one relation by another; so there is no way in Datalog to express a generic
parser. This demonstrates one of the key benefits of moving to a functional
language like Datafun. %\todo{contextualize utility of compound data more.}

%% Moreover, Datalog programs must be \emph{constructor-free}, to ensure all
%% relations are finite. Primitives such as \name{range} and \name{substring} violate
%% this restriction (as relations, they are infinite); it is not immediately
%% obvious that Datalog programs extended with these primitives remain terminating.
%% Our use of bounded fixed-points to guarantee termination is robust under such
%% extensions; as long as all primitive functions are total, Datafun programs
%% always terminate.

%% Finally, having computed a set via a fixed point, we can test whether
%% or not an element is in that set \emph{or not} -- the ability to test
%% for negative information after the fixed point computation completes
%% corresponds to a use of stratified negation in Datalog.


\subsection{Dataflow analysis}
\label{dataflow-analysis}

\todo{consider using naturals instead of integers for everything}

In this section, we show how some simple dataflow analyses can be
expressed in Datafun. We begin with the types in these programs.

\begin{code}
  \kw{type}~\typename{var} = \tstring\\
  \kw{type}~\typename{label} = \tint\\
  \kw{data}~\typename{op} = \ctor{eq} ~|~ \ctor{le}
  ~|~ \ctor{add} ~|~ \ctor{sub} ~|~ \ctor{mul} ~|~ \ctor{di\kern0pt v}\\
  \kw{data}~\typename{atom} = \ctor{v\kern0pt ar} \<\typename{var} ~|~ \ctor{num} \<\tint\\
  \kw{data}~\typename{expr} =
    \ctor{a\kern0pt t\kern0pt om} \<\typename{atom} ~|~
    \ctor{appl\kern0pt y} \<\typename{op} \<\typename{atom} \<\typename{atom}\\
  \kw{data}~\name{statement} =
    \ctor{assign} \<\typename{var} \<\typename{expr}
    ~|~ \ctor{if} \<\typename{expr} \<\typename{label} \<\typename{label}
  \\
  \kw{type}~\name{program} = \tset{\typename{label} \x \typename{statement}}
\end{code}

\noindent
We represent a \typename{program} as a set of nodes. Each node has a
\typename{label} and contains a \typename{statement}, either an assignment
(\ctor{assign}) or a conditional jump (\ctor{if}). Valid programs $p$ associate
any label $l$ with at most one node $(l,s) \in p$. In what follows, we use a few
trivial functions whose definitions we omit for space reasons. \todo{include
  these helpers' definitions}

\begin{code}
  \name{labels} \isa \typename{program} \to \tset{\typename{label}}\\
  %\name{vars} \isa \typename{program} \to \tset{\typename{var}}\\
  \name{uses} \isa \iso\typename{statement} \to \tset{\typename{var}}\\
  \name{defines} \isa \iso\typename{statement} \to \tset{\typename{var}}
\end{code}

\noindent
The \name{labels} function returns the set of labels in a program.
%The \name{vars} function returns the set of variables used in a program (both in expressions and as targets for assignments).
The \name{uses} function returns the set of variables used by the expressions in
a statement. The \name{defines} function returns the set of variables defined by
a statement (i.e., at most one variable -- the target of the assignment).

Given a program, we can recover its 1-step control flow graph with the
\name{flow} function:

\begin{code}
  \kw{type}~\typename{flow} = \tset{\typename{label} \x \typename{label}}\\
  \name{flow} \isa \typename{program} \to \typename{flow}\\
  \name{flow} \<\mvar p =
  \efor{\ptuple{\dvar i, \dvar s} \in \mvar p}\\
  \phantom{\name{flow} \<\mvar p = {}}
  \ematchif{\ctor{if} \<\pwild \<\dvar j \<\dvar k}{\dvar s}
  \\
  \phantom{\name{flow} \<\mvar p = {}}
  \ematchthen{\eset{(\dvar i, \dvar j),\, (\dvar i, \dvar k)}}
  \\
  \phantom{\name{flow} \<\mvar p = {}}
  \ematchelse{\esetfor{\etuple{\dvar i, \dvar i + 1}}{
  %%   \mem \<\ebox{\dvar i + 1} \<(\name{labels} \<\mvar p)
    \peq{(\dvar i + 1)} \in \name{labels} \<\mvar p
  }}
  %% \edcase{\dvar s} \ctor{if} \<\pwild \<\dvar j \<\dvar k
  %% \caseto \eset{(\dvar i, \dvar j),\, (\dvar i, \dvar k)}
  %% \\
  %% \phantom{\name{flow} \<\mvar p = \edcase{\dvar s}}
  %% \pwild \caseto \esetfor{\etuple{\dvar i, \dvar i + 1}}{
  %% %%   \mem \<\ebox{\dvar i + 1} \<(\name{labels} \<\mvar p)
  %%   \peq{(\dvar i + 1)} \in \name{labels} \<\mvar p
  %% }
\end{code}

\noindent
This says that if a program node $(i, s)$ is a conditional jump, $\ctor{if}
\<\pwild \<j \<k$, then it may flow to either $j$ or $k$; otherwise, it flows to
the next program position $i + 1$ if it exists.

Using this we can define liveness analysis, one of the classic backwards
dataflow analyses. The function \name{live} takes a program $\mvar p$ and its
flow graph $\mvar f$ and produces a set of label/variable pairs $(i,v)$
indicating that the variable $v$ is live at program point $i$.

\begin{code}
  \name{live} \isa \iso \typename{program} \to \iso \typename{flow} \to
  \tset{\typename{label} \x \typename{var}}\\
  \name{live} \<\pboxvarlong{program} \<\pboxvarlong{flow} = \\
  \quad \efixisraw{\mvar l}\\
  \quad \efor{\ptuple{\dvar i, \dvar s} \in \dvarlong{program}}\\
  \quad \phantom{{}\cup}
  (\eset{\dvar i} \x \name{uses}\<\dvar s)\\
  \quad
  \cup \esetfor{\etuple{\dvar i, \dvar v}}{
      \ptuple{\peqvar{i}, \dvar j} \in \dvarlong{flow},\,
      \ptuple{\peqvar{j}, \dvar v} \in \mvar l,\,
      \notmember{\dvar v}{(\name{defines} \<\dvar s)}
  }
  %%   \eset{i} \x (\name{uses}\<\dvar s \cup
  %%   \esetfor{\dvar v}{
  %%     \ptuple{\peqvar{i}, \dvar j} \in \dvarlong{flow},\,
  %%     \ptuple{\peqvar{j}, \dvar v} \in \mvar l,\,
  %%     \neg (\mem \<\ebox{\dvar v} \<(\name{defines} \<\dvar s))
  %%   })
\end{code}

\noindent
At each label $i$, a variable $v$ is live if either of two conditions holds: (1)
it is used by the current statement $s$, or (2) it is live at some label $j$ to
which $i$ flows, and which does not define the variable $v$ for itself.

Next we give one of the classic forwards dataflow analyses: reaching
definitions. This determines which program points the value assigned by a
particular statement (a ``definition'') can reach.

\nopagebreak[2]
\begin{code}
  \name{reaching} \isa \iso\typename{program} \to \iso\typename{flow} \to
  \tset{\typename{var} \x \typename{label} \x \typename{label}}\\
  \name{reaching} \<\pboxvarlong{program} \<\pboxvarlong{flow} =\\
  \quad \efixisraw{\mvar r}\\
  \quad \efor{\ptuple{\dvar k, \dvar s} \in \dvarlong{program}}\\
  \quad \phantom{{} \cup}
  \esetfor{\etuple{\dvar v, \dvar k, \dvar k}}{
    \dvar v \in \name{defines} \<\dvar s}
  \\
  \quad  \cup \esetfor{\etuple{\dvar v, \dvar i, \dvar k}}{
    \ptuple{\dvar j, \peqvar k} \in \dvarlong{flow},\,
    \ptuple{\dvar v, \dvar i, \peqvar j} \in \mvar r,\,
    \notmember{\dvar v}{(\name{defines} \<\dvar s)}
  }
\end{code}

\noindent
The function \name{reaching} takes a program and its flow graph, and returns a
set of tuples $(v, i, j)$ indicating that the definition of $v$ at $i$ might
reach the program point $j$. These tuples are generated by two rules,
corresponding to the two clauses in \name{reaching}'s inner loop: (1) if $v$ is
defined at $i$, then it reaches $i$, and (2) if the definition of $v$ at $i$
reaches $j$ and $j$ flows to $k$ then the definition also reaches $k$ unless $j$
has an intervening definition of $v$.
