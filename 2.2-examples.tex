\section{Examples}
\label{examples}

\input{2-figure-sugar}

For brevity and clarity, the examples that follow make use of some syntax sugar:

\begin{enumerate}

\item We mentioned earlier that Datafun's boolean type \tbool\ is ordered
  $\efalse < \etrue$. This is because we encode booleans as sets of empty
  tuples, $\tset 1$, with \efalse\ as the empty set $\esetraw{}$ and
  \etrue\ as the singleton $\esetraw{\etuple{}}$. On these sets \kw{for}
  degenerates to a ``one-sided'' conditional, $\ewhen b e$, yielding
  $e$ if $b$ is $\etrue$ and $\bot$ otherwise. Compared with encoding booleans
  as a sum type \(\tunit + \tunit\) and \kw{when} as \kw{case}, our approach has
  the advantage that \kw{when} is monotone in the condition $b$.

  \splittodo{do we ever use $\kw{when}$?}{YES: intersection example. but this might go away after rewrite. anywhere else? I think we only use conditions in set comprehensions and the like.}

\item We make use of set comprehensions, which can be desugared into the monadic
  operators \kw{for} and \kw{when} in the usual
  way~\cite{wadler-monad-comprehensions}.

%% \item It is convenient to treat \prim{fix} as a binding form, $\efixis x e$,
%%   rather than explicitly supplying a boxed function, $\efix\ebox{\fnof x e}$.

\item We make free use of curried functions and pattern matching. Desugaring
  these is relatively standard, and so we will say little about it, with one
  exception: the box-elimination form $\eletbox x e e'$ is a pattern matching
  form, and so we allow it to occur inside of patterns. The effect of a box
  pattern $\pbox{\isocolor p}$ is to ensure that all of the variables bound in
  the pattern $\isocolor p$ are treated as discrete variables.

\item \todo{equality patterns.}

\item \todo{algebraic datatypes}
\end{enumerate}

\noindent
We summarize the desugaring rules we use in \cref{figure-sugar} (except for
pattern matching and algebraic datatypes, which are standard).


\subsection{Set operations and relational algebra}
\label{set-operations-and-relational-algebra}

\todo{reorder this to introduce equality patterns.}

\newcommand\mem{\name{member}}

One of the main features of Datafun is that it permits manipulating
relations as first class values.
%
In this subsection we will show how a variety of standard operations on sets can
be represented in Datafun.
%
The first operation we consider is testing membership:

\begin{code}
  \mem \isa \iso \eqt A \to \tseteq A \to \tbool\\
  \mem \<\pboxvar x \<s = \efor{y}{s} \eeq {\dvar x} {\dvar y}
\end{code}

\noindent
This checks if $\dvar x$ is equal to any element $\dvar y \in s$. The argument
$\dvar x$ is discrete because increasing $\dvar x$ might send it from being
\emph{in} the set to being \emph{outside} the set: although $1 \le 2$ and
$1 \in \esetraw{1}$, nonetheless $2 \notin \esetraw{1}$. Notice that here we're
taking advantage of encoding booleans as sets of empty tuples -- unioning these
sets implements logical \emph{or}.

Next we turn to set union and intersection. Union is baked into Datafun as the
semilattice join, $x \cup y = x \vee y$, while intersection is definable using
\mem, by taking the union of every singleton $\esetraw{\dvar x}$ such that
$\dvar x$ is in both $s$ and $t$:

\newcommand\compose\bullet

\begin{code}
  \pwild \cap \pwild \isa \tseteq A \to \tseteq A \to \tseteq A\\
  %% NB. \kern -.5pt to get "member" closer to open paren.
  s \cap t = \efor x {s} \ewhen{\kern -.5pt \mem \<\eboxvar x \<t} \eset{\dvar x}
\end{code}

\noindent
Using comprehensions, this could alternately be written as:

\begin{code}
  s \cap t = \esetfor{\dvar x}{\dvar x \in s, \mem \<\eboxvar x \<t}
\end{code}

\noindent From now on, we'll use comprehensions whenever possible. For example, comprehensions make cross product and relational composition look almost exactly like their mathematical definitions:

\newcommand\bone{\dvar b_{\isocolor 1}}
\newcommand\btwo{\dvar b_{\isocolor 2}}
\newcommand\yone{\dvar y_{\isocolor 1}}
\newcommand\ytwo{\dvar y_{\isocolor 2}}

\newlength\functionskip \setlength{\functionskip}{1em}

\begin{code}
  \pwild \x \pwild \isa \tseteq A \to \tseteq B \to \tset{\eqt A \x \eqt B}\\
  %s \x t = \efor{x}{s} \efor{y}{t} \eset{\etuple{\dvar x, \dvar y}}
  s \x t = \esetfor{\etuple{\dvar x, \dvar y}}{\dvar x \in s,\, \dvar y \in t}
  \\[\functionskip]
  \pwild \compose \pwild \isa
  \tset{\eqt A \x \eqt B}
  \to \tset{\eqt B \x \eqt C}
  \to \tset{\eqt A \x \eqt C}\\
  s \compose t = \esetfor{\etuple{\dvar a, \dvar c}}{
    \ptuple{\dvar a, \bone} \in s,\,
    \ptuple{\btwo, \dvar c} \in t,\,
    \eeq \bone \btwo}
\end{code}

\noindent
The definitions of functional programming stalwarts \emph{filter} and \emph{map}
(or in relational algebra terms, \emph{select} and \emph{project}) are slightly
complicated by the need to be explicit about
(non-\nolinebreak[4])\linebreak[0]monotonicity:

\newcommand{\kernf}{\kern1.67pt f}
\newcommand{\kernfpost}{\kern.3pt}

\begin{code}
  \name{filter} \isa (\iso \eqt A \to \tbool) \to \tseteq A \to \tseteq A\\
  \name{filter} \<f \<s = \esetfor{\dvar x}{\dvar x \in s, f\<\ebox{\dvar x}}
  \\[\functionskip]
  \name{map} \isa \iso(\iso \eqt A \to \eqt B) \to \tseteq A \to \tseteq B\\
  % need some kerning between the [{ and the f
  \name{map} \<\pboxvar{\kernf\kernfpost} \<s = \esetfor{\dvar{\kernf}\<\ebox{\dvar x}}{\dvar x \in s}
\end{code}

\noindent
Why is \name{filter} monotone in its function argument while \name{map} is not? Recall that functions are ordered pointwise while sets are ordered by inclusion, and observe that increasing the filtering function (making it \emph{true} on more inputs) enlarges the result of \name{filter}, but the same does not hold for \name{map}: 

\[\begin{array}{rcccccr}
  \name{filter} \<(\le 0) \<\esetraw{0,1}
  &=& \esetraw{0}
  &\subseteq&
  \esetraw{0,1}
  &=&
  \name{filter} \<(\le 1) \<\esetraw{0,1}
  \\
  \name{map} \<(\le 0) \<\esetraw{0,1}
  &=&
  \esetraw{\etrue,\, \efalse}
  &\not\subseteq&
  \esetraw{\etrue}
  &=& \name{map} \<(\le 1) \<\esetraw{0,1}
\end{array}\]

\noindent
\todo{explain why neither map nor filter requires function to be monotone}

We can also define set difference, although we must first detour into boolean
negation:

\begin{code}
  {\neg} \isa \iso\tbool \to \tbool\\
  \neg \pboxvar t = \ecase{\eisempty{\dvar t}}
  \inj 1 \ptuple{} \caseto \etrue\:;\;\inj 2 \ptuple{} \caseto \efalse
  \\[1em] %TODO: right spacing?
  \pwild\setminus\pwild \isa \tseteq A \to \iso \tseteq A \to \tseteq A\\
  s \setminus \pboxvar t =
  \esetfor{\dvar x}{\dvar x \in s,\, \neg \ebox{\mem \<\eboxvar x \<\dvar t}}
\end{code}

\noindent
To implement boolean negation, we need the primitive operator $\eisempty e$,
which produces a tag indicating whether its argument $e$ (a boolean, i.e. a set
of empty tuples) is the empty set.
%
This in turn lets us define set difference, the analogue in Datafun of negation
in Datalog.
%
Note that in both boolean negation and set difference the ``negated'' argument
$\dvar t$ is boxed, because the operation is not monotone in $\dvar t$.
%
This enforces stratification.

Finally, generalizing the \name{ancestor} relation from the Datalog program in
\cref{section-datalog}, we can define the transitive closure of a relation:

\nopagebreak[2]
\begin{code}
  \name{trans} \isa \iso \tset{\eqt A \x \eqt A} \to \tset{\eqt A \x \eqt A}\\
  \name{trans} \<\pboxvar{edge} =
  \efixis{R}{\dvar{edge} \vee (\dvar{edge} \compose R)}
\end{code}

\noindent
This definition uses a least fixed point, just like the mathematical definition
-- a transitive closure is the least relation $R$ including both the original
relation $\dvar{edge}$ and the composition of $\dvar{edge}$ with $R$.
%
However, one feature of this definition peculiar to Datafun is that the argument
type is $\iso \tset{\eqt A \times \eqt A}$; the transitive closure takes a
\emph{discrete} relation.
%
This is because we must use the relation within the fixed point, and so its
parameter needs to be discrete to occur within.
%
This restriction is artificial -- transitive closure is semantically a monotone
operation -- but its explanation will have to wait until \todo{fwdref discreteness of fix}.


\subsection{Regular expression combinators}
\label{regular-expression-combinators}

\newcommand\tre{\typename{regex}}
\newcommand\tchar{\typename{char}}

Datafun permits tightly integrating the higher-order functional and bottom-up
logic programming styles. To illustrate the benefits of doing so, in this
section we implement a regular expression matching library in combinator style.
Like combinator parsers in functional languages, the code is very concise.
%
However, support for the relational style ensures we can write \naive\ code
\emph{without} the exponential backtracking cliffs typical of parser combinators
in functional languages.

For these examples we'll assume the existence of eqtypes \tstring, \tchar, and
\tint, an addition operator $+$, and functions \name{length} and \name{chars}
satisfying:

\begin{code}
  \name{length} \isa \iso\tstring \to \tint\\
  \name{length} \<\pboxvar{s} = \text{the length of }\dvar s
  \\[1em]
  \name{chars} \isa \iso\tstring \to \tset{\tint \x \tchar}\\
  \name{chars} \<\pboxvar{s} =
  \setfor{(i,c)}{\text{the $i$\textsuperscript{th}
      character of $\dvar s$ is $c$}}
\end{code}

\noindent
Note that by always boxing string arguments, we avoid committing ourselves to
any particular partial ordering on \tstring.

These assumed, we define the type of regular expression matchers:

\begin{code}
\kw{type}\ \tre = \iso \tstring \to \tset{\tint \times \tint}
\end{code}

\noindent
A regular expression takes a discrete string $\pboxvar s$ and returns the set of
all pairs $(i,j)$ such that the substring $\dvar s_i,\, \ldots,\, \dvar s_{j-1}$
matches the regular expression. For example, to find all matches for a single
character $c$, we return the range $(i,i+1)$ whenever $(i,c) \in
\name{chars}\<\eboxvar s$:

\begin{code}
  \name{sym} \isa \iso\tchar \to \tre\\
  \name{sym} \<\pboxvar c \<\pboxvar s =
  \esetfor{(\dvar i, \dvar i + 1)}{
    \ptuple{\dvar i, \dvar c'} \in \name{chars} \<\eboxvar s,\,
    \eeq{\dvar c}{\dvar{c'}}}
\end{code}

\noindent
To find all matches for the empty regex, i.e.\ all empty substrings, including
the one ``beyond the last character'':

\begin{code}
  \name{nil} \isa \tre\\
  \name{nil} \<\pboxvar s =
  \esetfor{\dvar i}{\ptuple{\dvar i, \pwild} \in \name{chars}\<\eboxvar s}
  \vee \eset{\name{length}\<\eboxvar s}
\end{code}

\noindent
Appending regexes $r_1, r_2$ amounts to relation composition, since we wish to
find all substrings consisting of adjacent substrings $s_i \ldots s_{j-1}$ and
$s_j \ldots s_{k-1}$ matching $r_1$ and $r_2$ respectively:

\nopagebreak[2]
\begin{code}
  \name{seq} \isa \tre \to \tre \to \tre\\
  \name{seq} \<r_1 \<r_2 \<s = r_1\<s \compose r_2\<s
\end{code}

\noindent
Similarly, regex alternation \texttt{r\textsubscript{1}|r\textsubscript{2}} is
accomplished by unioning all matches of each:

\nopagebreak[2]
\begin{code}
  \name{alt} \isa \tre \to \tre \to \tre\\
  \name{alt} \<r_1 \<r_2 \<s = r_1\<s \vee r_2\<s
\end{code}

\noindent
The most interesting regular expression combinator is Kleene star. Thinking
relationally, if we consider the set of pairs $(i,j)$ matching some regex
\texttt{r}, then \texttt{r*} matches its \emph{reflexive, transitive closure}.
This can be accomplished by combining \emph{nil} and \emph{trans}.

\nopagebreak[2]
\begin{code}
  \name{star} \isa \iso\tre \to \tre\\
  \name{star} \<\pboxvar r \<\pboxvar s =
  \name{nil}\<\eboxvar s \vee
  \name{trans} \<\ebox{\dvar r \<\eboxvar s}
\end{code}

\noindent
Note that the argument $\dvar r$ must be discrete because \name{trans} uses it
to compute a fixed point.\footnote{Technically the inclusion order on sets of
  integer pairs does not satisfy the ascending chain condition, so this use
  of \name{trans} is not well-typed. However, since the positions in a
  particular string form a finite set, semantically there is no issue.
  We will address this in \cref{section-nested-fixed-points}.}



\subsection{Regular expression combinators, take two}
\label{regular-expression-combinators-take-two}

\newcommand\kernj{\kern1pt j}

%% TODO: edit/rewrite this section, especially the bit about left recursion, it
%% needs to be clearer

The combinators in the previous section found \emph{all} matches
within a given substring, but often we are not interested in all
matches: we only want to know if a string can match starting at a
particular location. We can easily refactor the combinators above to
work in this style, which illustrates the benefits of tightly
integrating functional and relational styles of programming -- we can
use functions to manage strict input/output divisions, and relations
to manage nondeterminism and search.

\begin{code}
  \kw{type}\ \tre = \iso (\tstring \x \tint) \to \tset{\tint}
\end{code}

\noindent
Our new type of combinators takes a string and a starting position, and returns
a set of ending positions. For example, $\name{sym} \<\eboxvar c$ checks if
$\dvar c$ occurs at the start position $\dvar i$, yielding $\esetraw{\dvar i+1}$
if it does and the empty set otherwise, while \name{nil} simply returns the
start position $\dvar i$.

\nopagebreak[2]
\begin{code}
  \name{sym} \isa \iso\tchar \to \tre\\
  \name{sym} \<\pboxvar{c} \<\pboxtuple{\dvar{s}, \dvar{i}}
  = \esetfor{\dvar i+1}{
    \ptuple{\dvar{\kernj}, \dvar d}
    \in \name{chars} \<\eboxvar{s},\,
    \eeq {\dvar i} {\dvar j},\,
    \eeq {\dvar c} {\dvar {d\kern.5pt}}}
  \\[8pt]
  \name{nil} \isa \tre \to \tre\\
  \name{nil} \<\pboxtuple{\dvar{s}, \dvar{i}} = \eset{\dvar{i}}
\end{code}

\noindent
Appending regexes $\name{seq}\<r_1\<r_2$ simply applies $r_2$ starting from
every ending position that $r_1$ can find:

\nopagebreak[2]
\begin{code}
  \name{seq} \isa \tre \to \tre \to \tre\\
  \name{seq} \<r_1 \<r_2 \<\pboxtuple{\dvar{s}, \dvar{i}} =
  \efor{\kernj}{r_1\<\eboxtuple{\dvar{s}, \dvar{i}}}
  r_2 \<\eboxtuple{\dvar{s}, \dvar j}
\end{code}

\noindent
Regex alternation \name{alt} is effectively unchanged:

\nopagebreak[2]
\begin{code}
  \name{alt} \isa \tre \to \tre \to \tre\\
  \name{alt} \<r_1 \<r_2 \<x = r_1\<x \vee r_2\<x
\end{code}

\noindent
Finally, Kleene star is implemented by recursively appending $\dvar r$ to a
set $x$ of matches found so far:

\nopagebreak[2]
\begin{code}
  \name{star} \isa \iso\tre \to \tre\\
  \name{star} \<\pboxvar r \<\pboxtuple{\dvar{s}, \dvar{i}}
  = \efixis{x}{\bigl(\eset{\dvar{i}} \vee
    \efor {\kernj} {x} \dvar r\<\eboxtuple{\dvar{s}, \dvar j}
    \bigr)}
\end{code}

\noindent
It's worth noting that this definition is effectively \emph{left-recursive} --
it takes the endpoints from the fixed point $x$, and then continues matching
using the argument $\dvar r$. This should make clear that this is not just plain
old functional programming -- we are genuinely relying upon the fixed point
semantics of Datafun.


\subsection{CYK parsing}
\label{cyk-parsing}

\splittodo{This section needs several things.}{It wants equality patterns. It
  also needs explanations of various helper functions, including length,
  substring, and range. It also needs data type declaration. I need to sign post
  all these things in the appropriate place for each one.}

Parsing can be understood logically: a parse tree is a proof that a string
belongs to a language, and parsing is proof search~\cite{deductive-parsing}.
%
One of the simplest parsing algorithms is the Cocke-Younger-Kasami (CYK)
algorithm for parsing grammars in Chomsky normal form; that is, where each
production is either of the form $A \to B\,C$ or $A \to \vec{a}$, with $A,B,C$
ranging over nonterminals and $\vec{a}$ over strings of terminals.
%
Fix a Chomsky-normal grammar $G$ and a word $w = w_0 w_1 ... w_{n-1}$ to be parsed,
and write $w_{i..j}$ for the substring $w_i ... w_{j-1}$.
%
Now, we introduce a family of predicates $A(i,j)$ (sometimes called \emph{facts}
or \emph{items}), intended to represent the proposition that $w_{i..j}$ is
generated by the nonterminal $A$.
%
Then, we can specify the CYK algorithm with the following two inference rules:

%% TODO: the before/after spacing on this is off
\begin{mathpar}
  \inferrule*{(A \to B\,C) \in G \\ B(i, j) \\ C(j, k)}
             {A(i, k)}
  \and
  \inferrule*{(A \to \vec{a}) \in G \\ \vec{a} = w_{i..j}}
             {A(i,j)}
\end{mathpar}

\noindent
\todo{explain CYK rules.} Then the whole word $w$ is generated by the start
symbol $S$ if $S(0,n)$ is derivable.

In Datafun, this rule-based description of the algorithm can be transliterated
almost directly into code. We begin by introducing a few basic types.

%% TODO: figure this out
\newcommand\ctor[1]{\textsc{\lsstyle\MakeLowercase{#1}}}
\renewcommand\ctor[1]{\textsf{\scshape\MakeLowercase{\lsstyle#1}}}
\newcommand\tfact{\typename{fact}}
\newcommand\tsymbol{\typename{symbol}}
\newcommand\tgrammar{\typename{grammar}}

\begin{code}
\kw{type}~\tsymbol = \tstring\\
\kw{data}~\typename{rule}
= \ctor{String} \<\tstring
~|~ \ctor{Concat} \<\tsymbol \<\tsymbol\\
\kw{type}~\tgrammar = \tset{\tsymbol \x \typename{rule}}\\
\kw{type}~\tfact = \tsymbol \x \N \x \N\\
\end{code}

\noindent
The $\tsymbol$ type is a type synonym representing nonterminal names
with strings. The $\typename{rule}$ type is the type of the right-hand-sides
of productions in Chomsky normal form -- either a string, or a pair of
nonterminals. A $\tgrammar$ is just a set of productions -- a set
of pairs of nonterminals paired with their rules. The type $\tfact$
is the type representing the atomic facts derived by the CYK inference
system -- they are triples of the rulename, the start position, and
the end position.

\todo{we'll need helper functions}

\begin{code}
  \name{length} \isa \iso\tstring \to \tint\\
  \name{range} \isa \iso \tint \to \tint \to \tset{\tint}\\
  \name{substring} \isa \iso(\tstring \x \tint \x \tint) \to \tstring\\
  (+) \isa \tint \to \tint \to \tint\\
  (-) \isa \tint \to \iso\tint \to \tint
\end{code}

\noindent
With these types in hand, we can write the CYK algorithm as a fixed point
computation. In fact, it is convenient to break it into two pieces, by first
defining the function whose fixed point we take. So we can write down the
$\name{iter}$ function, which represents one step of the fixed point iteration.

\begin{code}
  \name{iter} \isa \iso \tstring \to \iso\tgrammar
  \to \tset{\tfact} \to \tset{\tfact}\\
  \name{iter} \<\pboxvar{text} \<\pboxvar{grammar} \<F =
  \\\phantom{\quad\cup{}} \{~\eiso{\etuple{\dvar A,\, \dvar i,\, \dvar k}}
  ~|~
  (\dvar A, \ctor{Concat} \<\dvar B \<\dvar C) \in \dvar{grammar},
  \etuple{\peq{\dvar B}, \dvar i, \dvar j} \in F,
  \etuple{\peq{\dvar C}, \peq{\dvar j}, \dvar k} \in F ~\}
  \\\quad\cup \{~
  \eiso{\etuple{\dvar A,\, \dvar i,\, \dvar i + \name{length}\<\dvar s}}
  \\\phantom{\quad\cup{}} |~
  (\dvar A, \ctor{String}\<\dvar s) \in \dvar{grammar},
  \\\phantom{\quad\cup{}} \phantom{|~}
  \dvar i \in \name{range} \<\ebox{0} \<(\name{length} \<\dvar{text} - \ebox{\name{length} \<\dvar s}),
  \\\phantom{\quad\cup{}} \phantom{|~} \dvar s =
  \name{substring} \<\ebox{\dvar{text},\, \dvar i,\, \dvar i + \name{length}\<\dvar s}
  ~\}
\end{code}

\noindent
We can then use $\name{iter}$ to implement the $\name{parse}$ function:

\begin{code}
  \name{parse} \isa \iso \tstring \to \iso \tgrammar \to \tset{\tsymbol}\\
  \name{parse} \>\pboxvar{text} \>\pboxvar{grammar} = \\
  \quad \elet{s = \efixis{c}{\name{iter} \<\ebox{\dvar{text}} \<\ebox{\dvar{grammar}} \<c}}\\
  \quad \esetfor{\dvar a}{\etuple{\dvar a, \peq 0, \dvar n} \in s, \eeq{\dvar n}{\name{length}\<\dvar{text}}}
\end{code}

\noindent
This finds all nonterminals in \name{grammar} that generate the entire string
\name{text}. \todo{more detail: why does parse work?}

%% This function just takes the fixed point of $\name{iter}$ --
%% almost. Because facts are triples $\tsymbol \x \N \x \N$, sets of
%% facts may in general grow unboundedly.  To ensure termination, we
%% construct a set $\m{bound}$ to bound the sets of facts we consider in
%% our fixed point computation, by bounding the symbols to names found in
%% the grammar \name{grammar}, and the indices to positions of the string. Since
%% all of these are finite, we know that the computation of $\name{chart}$
%% as a bounded fixed point will terminate. Then, having computed the
%% fixed point, we can check chart to see if $(a, 0, \name{length}\;\name{text})$
%% is derivable.

This program is not expressible in Datalog, because Datalog provides no way to
\emph{abstract} over grammars. The rules of a grammar are easily represented as
Datalog relations --- but since Datalog is first-order, it cannot parameterize
one relation by another; so there is no way in Datalog to express a generic
parser. This demonstrates one of the key benefits of moving to a functional
language like Datafun. \todo{contextualize utility of compound data more.}

%% Moreover, Datalog programs must be \emph{constructor-free}, to ensure all
%% relations are finite. Primitives such as \name{range} and \name{substring} violate
%% this restriction (as relations, they are infinite); it is not immediately
%% obvious that Datalog programs extended with these primitives remain terminating.
%% Our use of bounded fixed-points to guarantee termination is robust under such
%% extensions; as long as all primitive functions are total, Datafun programs
%% always terminate.

%% Finally, having computed a set via a fixed point, we can test whether
%% or not an element is in that set \emph{or not} -- the ability to test
%% for negative information after the fixed point computation completes
%% corresponds to a use of stratified negation in Datalog.


\subsection{Dataflow analysis}
\label{dataflow-analysis}

\todo{import dataflow analysis code from first Datafun paper}
