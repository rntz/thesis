\chapter{Introduction}


\section{Monotone fixed points}

%% \splittodo{sketch problem space:}{recursive queries + higher-order functions + a
%%   clean denotational semantics free of implementation details (``declarative'')
%%   + be able to reuse optimizations from the database and Datalog literature}

An extraordinary number of classic and useful computational problems can be
expressed as finding the least fixed point of a monotone map on a semilattice
satisfying the ascending chain condition. The utility of Datalog is explained by
the fact that it captures this pattern, albeit restricted to the semilattice of
finite sets under union. To understand this pattern better, let's consider three
examples of increasing complexity:
%
(1) reachability in a graph;
(2) single-source shortest paths;
and (3) analyzing which variable assignments may reach a given line in a simple
imperative program (often called ``reaching definitions'').

%% \paragraph{Reachability} Consider a graph and suppose we wish to find all nodes reachable from some
%% designated start node~(\cref{figure-reachability}).

%% \paragraph{Shortest paths} blha blah

\begin{description}
\item[Reachability] % \strong{Reachability.}
%
Consider a graph and suppose we wish to find all nodes reachable from some
designated start node~(\cref{figure-reachability}). We proceed as follows:
first, we put a check mark next to the start node; then, repeatedly, we pick a
node and put a check next to it if any of its neighbors is checked. Once there
are no nodes which we can mark this way -- in particular, when there are no
edges between checked and unchecked nodes -- we are done; the reachable nodes
are exactly the checked nodes.

%% parsep: \the\parsep\\
%% itemsep: \the\itemsep

%% whenever you see an edge between a marked and an
%% unmarked node, mark the unmarked node. Once there are no edges between marked
%% and unmarked nodes -- and thus no possibility of any node becoming marked -- we
%% are done.

\begin{figure}[pth]
  \centering
  \XXX
  \caption{Graph reachability}
  \label{figure-reachability}
\end{figure}


\item[Shortest paths]
%
Now suppose each edge $e$ in the graph has an associated non-negative length
$d_e$, and we wish to find the minimum distance to each reachable
node~(\cref{figure-shortest-paths}). We use a small modification of the previous
procedure: instead of a check mark, we annotate nodes $v$ with the length $d_v$
of the shortest path to them we've discovered so far. Initially we mark the
start node with 0 and every other node with $\infty$ (representing ``no known
path'').
%
%% Then, repeatedly, we pick a node $u$ and relax its annotation by examining its
%% neighborhood: in particular, we take the minimum among incoming edges $v
%% \xrightarrow{e} u$ of the sum $d_v + d_e$ where $d_v$ is the annotation on $v$
%% and $d_e$ is the length of the edge $e$.
%
%% Then, whenever we see an edge providing a shorter path to a node than its
%% current annotation, we update it appropriately -- that is, if we see an edge $e$
%% with length $d_e$ between nodes $v$ and $u$ with annotations $d_v, d_u$
%% respectively, we may update $d_u := \min(d_u, d_v + d_e)$.
%
Then, whenever an edge provides a shorter path to a node, we update its
annotation -- that is, for any edge $v \xrightarrow{e} u$ we may update $d_u :=
\min(d_u, d_v + d_e)$.
%
Once no shortening edges exist, the annotations $d_v$ cannot change, and we are done.%
%
%% Once this process stabilizes -- in particular, once there are no edges which
%% could shorten any annotation -- we are done.%
%
\footnote{The classic algorithm for single-source shortest paths, Dijkstra's
  algorithm, can be seen as a version of the algorithm we've described, but with
  a crucial optimization: it prioritizes which edges to consider next in a
  way that guarantees it never needs to revisit a node.}

\begin{figure}[pth]
  \centering
  \XXX
  \caption{Shortest paths}
  \label{figure-shortest-paths}
\end{figure}


\item[Reaching definitions]
%
Finally, let's consider something seemingly completely different: statically
analyzing a simple imperative program~(\cref{figure-reaching-definitions}).
%
%% In particular, we wish to determine which assignments may reach a given program
%% line; for example, the \texttt{print} on line 4 may observe the values of
%% \texttt{x} assigned on lines 1 and 5 and the value of \texttt{c} assigned on
%% line 2, but will never observe the value of \texttt{c} assigned on line 6.
%
In particular, we wish to determine which assignments may reach a given program
line; for example, the \texttt{print} on line 2 will receive only the value of
\texttt{x} assigned on line 1, while the \texttt{print} on line 4 may receive
the values assigned on both lines 1 and 5.

We determine this by propagating information along the control flow graph of our
program.
%
At each line we maintain a set of assignments (line-number/variable pairs) that
we know can reach that line.
%
Each line collects the assignments from all lines that can transfer control to
it -- usually the immediately preceding line, but loops and conditionals
complicate this.
%
However, lines which assign to a variable add themselves to this set, and discard other assignments to the same variable from incoming lines.

Once there is no line whose corresponding assignment-set is changing, the analysis is finished.
%
See \cref{figure-reaching-definitions-execution} for a step-by-step diagram of this process. \todo{describe the diagrams}

\begin{figure}[pt]
  \centering
  \ttfamily
  \begin{tabular}{cl}
    1 & \tt x := 0\\
    2 & \tt print x\\
    3 & \tt while true do\\
    4 & \tt\quad print x\\
    5 & \tt\quad x := x + 1
  \end{tabular}
  \caption{Example program}
  \label{figure-reaching-definitions}
\end{figure}

\input{1-figure-reaching-definitions-execution}

\end{description}

%\vspace{\baselineskip}
\noindent
How do these three examples fit into our proposed pattern: finding the least fixed point of a monotone map on a semilattice satisfying the ascending chain condition? Let's break down each point in turn:
%% These three examples can all be characterized as finding the least fixed point of a monotone map on a semilattice satisfying the ascending chain condition.

\begin{description}
\item[Fixed points]

  In each example, we maintained some state -- check marks or distance
  annotations on nodes, sets of reaching assignments on lines -- that changed
  over time, and we terminated when there was no action we could take -- no
  node, edge, or line we could examine -- which would change this state. In
  other words, we halted once our state was \emph{fixed} under our transition
  function.

  To make this more precise, \todo{formalize this transition function?}
  
\item[Monotone]

  Although our state changed over time, it did not change in arbitrary ways:
  there was a direction to it. Nodes went from unchecked to checked; distances
  to nodes decreased; and sets of reaching assignments grew.

  We can formalize this by giving our states a \emph{partial order} representing
  the direction they change as computation progresses and information increases.
  For example, in graph reachability, a node's state was a boolean flag; for
  simplicity we'll regard it as \etrue\ if the node is checked,
  \efalse\ otherwise. Since nodes go from unchecked to checked but not
  vice-versa, we say that $\efalse < \etrue$. \XXX

  \todo{need something about least-ness?}
  

\item[Semilattices] In each example, we had some way of combining information
  from multiple sources. In graph reachability, we marked a node if \emph{any}
  of its neighboring nodes were marked; in shortest paths, when there were
  multiple edges/paths into a node, we took the \emph{minimum} among these
  competing options; and in reaching definitions, when a line could receive
  control from multiple lines, we took the \emph{union} of their reaching
  assignment sets.

  Not coincidentally, these operations -- boolean disjunction, minimum, and
  union respectively -- are the \emph{least upper bound} operators for the
  partial orders we imposed on our states, making those partial orders into
  \emph{join-semilattices}.
%
  In general, we write $x \vee y$ for the least upper bound/semilattice join of
  $x$ and $y$. If our partial order represents the direction of increasing
  information, $x \vee y$ is a natural way to combine information: it includes
  all information from (is greater than) both $x$ and $y$, but does not jump to
  unnecessary conclusions -- it is the \emph{least}, most conservative, upper
  bound.

\item[Ascending chain condition] Finally, in each case there was a limit on how
  much information we could possibly learn, and thus how many transitions we
  could take. For instance, in graph reachability, there were finitely many
  nodes, and each node could only transition from unchecked to checked once.
%
  This argument can be formalized by showing our partial order on states obeys
  the \emph{ascending chain condition} (ACC), which asserts that there are no
  infinite strictly ascending chains, $x_0 < x_1 < x_2 < \dots$; consequently,
  any process producing an increasing state-sequence must halt.
%
  We leave it as an exercise for the reader to convince themselves each of our
  examples satisfies this property. \todo{need to show it here?}
\end{description}

\noindent
\splittodo{finish section.}{Note that monotonicity + ACC gives us a proof of termination: always go in a direction, can't go forever => must halt. furthermore can prove using a weak, easy-to-prove variant of Knaster-Tarski we find \emph{least} fixed point.}

\todo{missing segue}


\section{Datalog}
\label{section-datalog}

Datalog may be seen either as a restricted logic programming language or an
expressive database query language. To start with, we consider the former view,
explaining Datalog in terms of deduction. Here is a simple Datalog program:

\begin{datalog}
  \atom{parent}{\datum{alice}, \datum{bob}}.
  \\
  \atom{parent}{\datum{bob}, \datum{charlie}}.
  \\
  \atom{grandparent}{X, Z} \gets \atom{parent}{X, Y} \conj \atom{parent}{Y, Z}.
\end{datalog}

\noindent
We can see each line, or clause, of this program as an inference rule. The first
two lines are axioms, or inference rules with no premises; the last line is a
rule with two premises. In inference rule notation we might write this:
%
\begin{mathpar}
  \infer{~}{\atom{parent}{\datum{alice}, \datum{bob}}}

  \infer{~}{\atom{parent}{\datum{bob}, \datum{charlie}}}

  \infer{\atom{parent}{X, Y} \\ \atom{parent}{Y, Z}}{\atom{grandparent}{X, Z}}
\end{mathpar}

\noindent
More formally, a Datalog program is a sequence of \emph{clauses} terminated by
periods. Each clause is an implication with one conclusion and an optional list
of premises, written conclusion-first, ``$B \gets A_1 \conj A_2 \conj ... \conj
A_n.$''; or if there are no premises, simply ``$B.$''. The premises and
conclusion are \emph{atoms} of first-order logic: a predicate applied to a
sequence of arguments, $P(X_1, ..., X_n)$, or a negation of the same, $\neg
P(X_1, ..., X_n)$, where each argument must either be a variable (generally
written as an uppercase letter $X,Y,Z$) or a constant (written in lower case
sans-serif: $\datum{alice}, \datum{bob}, \datum{charlie}$). Moreover, the
conclusion of a clause must be positive, not negated.

As is the convention when interpreting inference rules, in Datalog the variables
in a clause are considered to be universally quantified: the logical
interpretation of our third line, for example, is $\fa{X, Y, Z} \atom{parent}{X,
  Y} \wedge \atom{parent}{Y, Z} \implies \atom{grandparent}{X, Z}$.

Occasionally we will consider Datalog programs which slightly relax some of
these requirements, for example by allowing premises which are notated infix,
for example $X = Y$ or $X < Y$.

Informally, the intended interpretation of a Datalog program is the set of all
facts deducible from its clauses. We access this set via \emph{queries}, for
example $\atom{grandparent}{\datum{alice},X}$, which asks for a list of all $X$
such that $\atom{grandparent}{\datum{alice},X}$ is deriveable. In general we
allow conjunctive queries: lists of atoms conjuncted together, for instance the
unlikely query $\atom{parent}{X,Y} \conj \atom{parent}{Y,X}$, which asks for a
pair of people who are each the parent of the other (or, in the case $X = Y$, a
single person who is their own parent). Finally, a query without any variables,
such as $\atom{grandparent}{\datum{charlie}, \datum{alice}}$, amounts to asking a
yes-or-no question: is the query deriveable or not?

\todo{something about least fixed point semantics}



\subsection{Termination and recursion}

Thus far our description of Datalog has not distinguished it from its ancestor
Prolog; this is because the difference lies not so much in their syntax as in
their semantics.
%
Without further restrictions, whether a proposition is deducible from a
collection of clauses is in general undecidable.
%
Prolog's solution is to specify its proof search strategy.
%
This lets Prolog programmers reason about the execution of their programs, but
it can mean that some logically sensible recursive programs fail to terminate.
For example:

\begin{datalog}
\atom{path}{X,Z} \gets \atom{path}{X,Y} \conj \atom{path}{Y,Z}.\\
\atom{path}{X,Y} \gets \atom{edge}{X,Y}.
\end{datalog}

\noindent
Read as inference rules, these clauses make \name{path} the transitive closure
of \name{edge}.
%
In Prolog, however, any query to \name{path} will loop.
%
This is because Prolog uses backward chaining (also called goal-directed or
top-down) depth-first search: we start from a goal and reason backward, applying
rules that might prove it.
%
These rules are applied in the order they occur in the program, so to solve the
query $\atom{path}{\datum{st-louis}, \datum{detroit}}$, Prolog will apply the
first rule and try recursively to solve $\atom{path}{\datum{st-louis},Y}$ for
unknown $Y$.
%
This in turn will apply the same rule, solving $\atom{path}{\datum{st-louis},
  Y_2}$ for unknown $Y_2$, which will solve $\atom{path}{\datum{st-louis}, Y_3}$
for unknown $Y_3$, and so on indefinitely.%
%
\footnote{One natural approach to this problem is to keep backward chaining, but
  use a complete search strategy instead of depth-first search; this is the
  approach adopted by miniKanren~\citep{kanren}. This restores some
  declarativeness to logic programming; in particular, reordering rules can no
  longer cause unproductive infinite looping. However, introducing a
  ``redundant'' rule like $\atom{path}{X,Y} \gets \atom{path}{X,Y}$ will still
  cause proof search to continue indefinitely (although it won't prevent any
  proofs from being found). And while this example is contrived, the problem in
  general is fundamental: without further limitations on clauses, proof search
  is only semi-decidable, so while complete search strategies can guarantee
  finding all proofs, they cannot guarantee they'll \emph{halt} after doing so.
  This is particularly important for the handling of negation-as-failure; see
  \cref{section-stratified-negation}.}

Datalog takes a different tack: rather than fix a proof search strategy, it
imposes limitations that keep proof search decidable. In particular, ignoring
for now the issue of negation, it imposes two restrictions which keep all
\todo{haven't explained the word relation} relations finite:

\begin{enumerate}
\item Clauses are \emph{range-restricted:} all variables in the conclusion of a
  clause must occur positively in its premises. For example, the premiseless
  clause ``$\atom{path}{X,X}.$'' is disallowed; while logically sensible (it
  asserts $\name{path}$ is reflexive), it leaves the variable $X$ unconstrained,
  which would generate an infinite relation.

\item Programs are \emph{constructor-free:} predicate arguments are either
  atomic terms or variables. This prevents the introduction of new terms that
  don't already appear in the program, as this could also result in an infinite
  relation; for example, the relation containing all digit-lists (the use of a
  `constructor' is highlighted in {\color{Red}red}):

  \nopagebreak[3]
  \begin{datalog}
    \atom{digits}{\datum{nil}}.
    \\
    \atom{digits}{{\color{Red}\datum{cons}(X, Xs)}} \gets
    \atom{digit}{X} \conj \atom{digits}{Xs}.
  \end{datalog}
\end{enumerate}

\noindent
Together, range-restriction and constructor-freedom ensure that relations are
\emph{finite}. This permits the most common Datalog implementation strategy,
\emph{forward chaining}.
%
In backward chaining we start from a goal (``is there a path from St.
Louis to Detroit?'') and reason backward, applying rules that might prove it.
%
In forward chaining, we start from what we know (``there's a path from
St. Louis to Chicago, and another from Chicago to Detroit'') and apply rules
whose premises are satisfied.

The weakness of forward chaining is that it's undirected: it deduces everything
it can! If all you want to know is whether you can reach Detroit from St. Louis,
this is wasteful. On the other hand, it's much easier to know when to stop: when
there is no rule whose application yields a new fact. This is the operational
justification for range-restriction and constructor-freedom: by ensuring all
predicates are finite, we guarantee forward-chaining deduction terminates.%
%
\footnote{\todo{talk about tabling, as a mixture of forward- and backward-chaining}}

\todo{missing a segue here}


\subsection{Stratified negation}
\label{section-stratified-negation}

Negation and deduction have an interesting relationship.
%
Consider the following program:

\nopagebreak[1]
\begin{datalog}
  \atom{underiveable}{} \gets \neg \atom{underiveable}{}.
\end{datalog}

\noindent
In classical logic, an implication $B \gets A$ is equivalent to $B \vee \neg A$.
Applying this, the above is equivalent to $\atom{underiveable}{} \vee
\neg\neg\atom{underiveable}{}$, and thus simply to $\atom{underiveable}{}$.
%
Regarded as a rule of inference, however -- as a strategy for deriving new facts
from ones already known -- this clause makes little sense: we cannot invoke it
unless we have proved its conclusion is false!

To avoid this sort of gap between the logical meaning of a program and its
interpretation as inference rules, Datalog allows only programs where uses of
negation can be \emph{stratified:} a recursively defined predicate (or mutually
recursive group of predicates) cannot use its own negation in its definition. 

This restriction also avoids the need to make arbitrary choices. For example,
this is disallowed:

\nopagebreak[1]
\begin{datalog}
  \atom{marry-rochester}{} \gets \neg \atom{marry-st-john}{}.\\
  \atom{marry-st-john}{} \gets \neg \atom{marry-rochester}{}.
\end{datalog}

This is classically equivalent to $\atom{marry-rochester}{} \vee
\atom{marry-st-john}{}$. While sensible logically, this means answering simple
yes-or-no queries requires making an arbitrary choice: if we query the
propositions $\atom{marry-rochester}{}$ and $\atom{marry-st-john}{}$ we
may consistently answer either \emph{Rochester} or \emph{St John} or
\emph{both}.
%
The symmetry of our program makes answering either
\emph{Rochester} or \emph{St John} unprincipled, and \emph{both} is simply
not deriveable from the given rules.%
%
\footnote{\todo{talk about answer-set programming?}}

Thus, unlike the preceding restrictions, stratified negation is not about
finiteness or decidability; rather, it is motivated by interpreting a program
as a set of rules for deduction and not merely a set of propositions. In other
words, in Datalog \emph{truth} is identified with \emph{deriveability}.

Following this principle, we regard anything not deriveable as false. This
conforms with the programmer's expectation that anything not explicitly
declared to be true is false. For example, returning to our example program
defining the paths through a graph:

\nopagebreak[1]
\begin{datalogarray}
  \atom{path}{X,Z} &\gets& \atom{path}{X,Y} \conj \atom{path}{Y,Z}.\\
  \atom{path}{X,Y} &\gets& \atom{edge}{X,Y}.
\end{datalogarray}

\noindent
Regarded as mere propositions, these implications do not rule out the
possibility that $\atom{path}{X,Y}$ is true for all vertices $X,Y$, regardless
of the \name{edge} relation (in other words, one model of these propositions
makes \name{path} the complete relation). But this is clearly not the
programmer's intent, which is to capture reachability under the \name{edge}
relation: not every graph is completely connected!

The principle of regarding anything not deriveable as false is known as
\emph{negation as failure:} to derive $\neg \atom{path}{X,Y}$ it suffices to
attempt to derive $\atom{path}{X,Y}$ and fail.
%
Forward-chaining provides a natural implementation strategy for
negation-as-failure: once we have deduced all facts of the form
$\atom{path}{X,Y}$, if a particular such fact was not deduced, for example
$\atom{path}{\datum{detroit}, \datum{\textalpha-centauri}}$, we regard this as
proof of its negation.

However, because a forward-chaining system must wait until all facts
$\atom{path}{X,Y}$ are deduced before handling negative queries
$\neg\atom{path}{X,Y}$, it cannot handle such negative queries in \name{path}'s
own definition.
%
This is the operational justification for stratified negation: we must be able
to stratify our Datalog program into layers, each of which may only use the
negation of predicates defined in the preceding layers.

\todo{something about stratification \& monotonicity}

%% Stratified negation thus ensures that it is possible for truth to coincide with
%% deriveability, and falsehood with underiveability (in model-theoretic terms, it
%% ensures the unique existence of a minimal model).


\section{What Datalog is good for}

\splittodo{in order, using examples:}{
  \begin{enumerate}
  \item simple sql-style queries, business analytics, use simple examples. Check Flix website? LogicBlox?
  \item monotone fixpt as long as the semilattice is sets; demonstrate
    reachability and reaching definitions
  \item scalable static analysis, eg: doop, semmle
  \end{enumerate}
}

\begin{datalog}
  \atom{reachable}{\datum{start}}.\\
  \atom{reachable}{Y} \gets \atom{reachable}{X} \conj \atom{edge}{X,Y}.
\end{datalog}

\subsection{Static analysis}

Datalog makes defining static analyses remarkably easy. For instance, the
essence of our third example, reaching definitions analysis, can be expressed in
Datalog as follows:

\begin{datalog}
  \atom{reaches}{L,V,L} \gets \atom{assigns}{L,V}.
  \\
  \atom{reaches}{L_{\textsf{dest}}, V, L_{\textsf{src}}}
  \gets
  \neg\atom{assigns}{L_{\textsf{dest}}, V}
  \conj
  \atom{reaches}{L_{\textsf{prev}}, V, L_{\textsf{src}}}
  \conj 
  \atom{flows}{L_{\textsf{prev}}, L_{\textsf{dest}}}.
\end{datalog}

\noindent
If $\atom{flows}{L_1, L_2}$ means that line $L_1$ may transfer control to $L_2$,
and $\atom{assigns}{L, V}$ means that line $L$ assigns to variable $V$, the
above defines $\atom{reaches}{L_{\textsf{dest}}, V, L_{\textsf{src}}}$ to mean
that the assignment to $V$ at line $L_{\textsf{src}}$ may reach
$L_{\textsf{dest}}$.

This fluency at defining static analyses is not limited to toy examples.
\todo{explain:} bddbddb~\citep{whaley-lam,DBLP:conf/aplas/WhaleyACL05}, Semmle,
DOOP~\citep{DBLP:conf/datalog/SmaragdakisB10}

\todo{discussion}

\citet{DBLP:conf/datalog/SmaragdakisB10} list several reasons why they found
Datalog to be useful when implementing a scalable points-to analysis, compared
in particular with a conventional language like Java or C++:

\begin{enumerate}
\item handles mutually-recursive relation definitions, which is common in static
  analysis. \emph{``Mutual recursion is the source of all complexity in program
    analysis. For a standard example, the logic for computing a callgraph
    depends on having points-to information for pointer expressions, which, in
    turn, requires a callgraph.''}~\citep{DBLP:conf/datalog/SmaragdakisB10}

\item Allows experimenting with implementation techniques without having to rewrite your program, e.g. BDD versus explicit representations of relations, different indexing strategies; or while making very small changes (compared to a lower level implementation language)

\item Query optimisation of individual rules being performed automatically, as
  opposed to having to hand optimize it: \emph{``We relied on query optimization
    (i.e., intra-rule, as opposed to inter-rule, optimization) being performed
    automatically. This was crucial for performance and, although a
    straightforward optimization in the context of database relations, results
    in far more automation than programming in a mainstream high-level
    language.''}

\item concision: \emph{``Generally, the declarative nature of \textsc{Doop}
  often allows for very concise specifications of analyses. We show in an
  earlier publication the striking example of the logic for the Java cast
  checking---i.e., the answer to the question “can type A be cast to type B?”
  The Datalog rules are almost an exact transcription of the Java
  Language Specification.''}

  \emph{``[W]e believe that our ability to efficiently optimize our
    implementation was largely due to the declarative specifications of
    analyses. Working at the Datalog level eliminated much of the artificial
    complexity of a points-to analysis implementation, allowing us to
    concentrate on indexing optimizations and on the algorithmic essence of each
    analysis.''}
\end{enumerate}


\section{What Datalog can't do}

\splittodo{what Datalog can't do:}{
  \begin{enumerate}
  \item semilattices other than sets (e.g. shortest paths)
  \item functional abstraction
  \item aggregations
  \item arithmetic or other functions
  \item compound data
  \end{enumerate}

  Often extended to handle aggregations, arithmetic, and compound data; but of
  course this gives up its semantics; or does it?
}

\cite{DBLP:conf/datalog/SmaragdakisB10}: they needed to add a macro system in
order to handle deep contexts, because Datalog does not support combining
multiple values into one, so they have to add an extra parameter to a predicate
for each component of the context.

\emph{``For deeper contexts, one needs to add extra variables, since pure
  Datalog does not allow constructors and therefore cannot support value
  combination. We have introduced in \textsc{Doop} a macro system to hide the
  number of context elements so that such variations do not pollute the analysis
  logic.''}

They also mention possibly wanting expressiveness enhancements: \emph{``The
  language needs to be developed as a real programming language, with [...], and
  possibly expressiveness enhancements (e.g., macros, exponential-search, or
  other high-order capabilities).''}


\subsection{Functional abstraction}

Consider our graph-reachability example again:

\begin{datalog}
  \atom{reachable}{\datum{start}}.\\
  \atom{reachable}{Y} \gets \atom{reachable}{X} \conj \atom{edge}{X,Y}.
\end{datalog}

\noindent
Suppose we wish to compute reachability over multiple different graphs. One way is to repeat ourselves:

\nopagebreak[2]
\begin{datalog}
  \atom{reachable1}{\datum{start1}}.\\
  \atom{reachable1}{Y} \gets \atom{reachable}{X} \conj \atom{edge1}{X,Y}.
  \\[1ex]
  \atom{reachable2}{\datum{start2}}.\\
  \atom{reachable2}{Y} \gets \atom{reachable}{X} \conj \atom{edge2}{X,Y}.
  \\[1ex]
  \atom{reachable3}{\datum{start3}}.\\
  \atom{reachable3}{Y} \gets \atom{reachable}{X} \conj \atom{edge3}{X,Y}.
  \\
  \qquad\vdots
\end{datalog}

\noindent
This could quickly get out of hand if you want to do this more than a handful of
times, especially if you want to repeat something more complex than a two-liner
like graph reachability.
%
In any ordinary language, we would factor out this repeated code into a procedure or a function.

Unfortunately, Datalog cannot do this.
%
Datalog does not have functions, procedures, or modules, only relations; and
relations are first-order, unable to manipulate or abstract over other relations.
%
This first-order restriction on relations is crucial to making Datalog evaluation tractable while maintaining its straightforward semantics; higher-order logic programming is an open research problem \todo{CITE}. \XXX



\subsection{Semilattices other than set union}

We have shown how to define reachability and reaching-definitions in Datalog.
What about our second example, single-source shortest paths? A naive approach at
expressing this in Datalog might look like this:

\begin{datalog}
  \atom{shortest}{\datum{start}, 0}.\\
  \atom{shortest}{Y, D_3} \gets
  \atom{shortest}{X, D_1} \conj
  \atom{edge}{X,Y,D_2} \conj
  D_1 + D_2 = D_3.
\end{datalog}

\noindent
One problem with this example is the use of the infinite relation $D_1 + D_2 =
D_3$; recall that infinite relations can cause a problem for a forward-chaining
evaluator. However, this particular case can be implemented, since $D_1$ and
$D_2$ are supplied by the other premises, and together these allow computing
$D_3$.%
\footnote{\splittodo{Cite Mistral Contrastin's work}{ on dataflow/mode systems for Datalog?}}
%
The bigger problem is that, despite its name, the relation $\atom{shortest}{X,
  D}$ as defined above finds all distances $D$ from \datum{start} to $X$ rather
than only the shortest. Besides failing to express our intent, this relation may
be infinite if there are cycles in our graph, and computing it will loop.

Datalog really only understands one semilattice -- finite sets under union --
and has no way to specify that multiple sources of information, like the
distance $D$ in $\atom{shortest}{X,D}$, should be combined using a different
strategy. This puts any computation using a custom semilattice out of reach.
This particularly restricts Datalog's application to static analysis,
\todo{abstract interpretation, other semilattices}.


\section{Our goal}

\splittodo{our goal:}{ease these limitations by combining Datalog with
  functional programming. From this we can gain: semantics a la carte, more
  compositional approach to guarantees; functions to factor out repetition;
  types to describe \& hopefully handle other semilattices in a principled way;
  compound data via datatypes}


\section{Datalog by example}

\splittodo{FIXME: remove this section}{ and move relevant content into other sections if useful}

Ideas for Datalog examples:
\begin{itemize}
\item some simple business logic examples, department-employee stuff
\item transitive closure, of course; maybe a less contrived example
\item sketch a points-to analysis? DOOP?
\item find things that people use souffle for? Look through Semmle papers? Check will crichton's site?
\end{itemize}

\noindent
\textbf{possible example programs}

\begin{datalog}
  \atom{grandparent}{X,Z} \gets \atom{parent}{X,Y} \conj \atom{parent}{Y,Z}.
  \\
  \atom{sibling}{Y,Z} \gets \atom{parent}{X,Y} \conj \atom{parent}{X,Z} \conj Y \ne Z.
  \\
\end{datalog}
\begin{datalog}
  \atom{hasparent}{Y} \gets \atom{parent}{X,Y}.
  \\
  \atom{orphan}{Y} \gets \neg\atom{hasparent}{Y}.
\end{datalog}
\begin{datalog}
  \atom{possibly-overpaid}{Y} \gets
  \atom{manages}{X,Y} \conj \atom{salary}{X,S_1}
  \conj \atom{salary}{Y,S_2} \conj S_1 < S_2.
  \\
  \atom{cross-department}{X,Y} \gets
  \atom{department}{X,D_1} \conj \atom{department}{Y,D_2} \conj
  \\
  \phantom{\atom{cross-department}{X,Y} \gets {}}
  \atom{manages}{X,Y} \conj D_1 \ne D_2.
\end{datalog}

\begin{datalog}
  \atom{purchased-every-food}{P}
  \gets
  \atom{buyer}{P} \conj \neg\atom{unpurchased}{P}.
  \\
  \atom{unpurchased}{P}
  \gets
  \atom{buyer}{P}  \conj \atom{food}{F} \conj \neg\atom{purchased}{P,F}.
\end{datalog}

\noindent
\splittodo{use unique drinkers as datafun example?}{ it should involve much less redundancy
  in datafun}

\begin{datalog}
  \atom{unique-drinker}{D} \gets
  \atom{drinker}{D} \conj \neg\atom{has-twin}{D}.
  \\
  \atom{has-twin}{D} \gets \atom{drinker}{D} \conj \atom{drinker}{E}
  \conj D \ne E
  \conj \neg\atom{differs}{D,E}.
  \\
  \atom{differs}{D,E} \gets
  \atom{drinker}{E} \conj \atom{likes}{D,B} \conj \neg\atom{likes}{E,B}.
  \\
  \atom{differs}{D,E} \gets
  \atom{drinker}{D} \conj \neg\atom{likes}{D,B} \conj \atom{likes}{E,B}.
\end{datalog}

\begin{code}
  \name{unique-drinkers} \isa \tset{\typename{person}}\\
  \name{unique-drinkers} =
  \esetfor{\dvar d}{
    \dvar d \in \name{drinkers},\,
    \neg\ebox{
      \eforvar{e}{\name{drinkers}}
      \eiso{\dvar d \ne \dvar e} \cap
      \name{same} \<\eboxtuple{\dvar d, \dvar e}
    }}
  \\[\betweenfunctionskip]
  \name{same} \isa \iso(\typename{person} \x \typename{person}) \to \tbool\\
  \name{same} \<\pboxtuple{\dvar d, \dvar e} =
  \eeq{
    \esetfor{\dvar b}{\ptuple{\peqvar{d}, \dvar b} \in \name{likes}}
  }{
    \esetfor{\dvar b}{\ptuple{\peqvar{e}, \dvar b} \in \name{likes}}
  }
\end{code}

\noindent
possible examples: intersection, union, relational join, filter, map, constructing a control flow graph, reaching definitions, unique drinkers, purchased-all-items, directors of movies tom hanks starred in
