%% \section{From semi\naive{} evaluation to the incremental \boldfn-calculus}


\section{Semi\naive\ evaluation as incremental computation}
\label{section-seminaive-incremental}

\todolater{replace this with single-source reachability?}

Consider the following Datalog program:

%% Let's return to our example Datalog program~\todo{cross reference Datalog
%%   transitive closure example}, modified to consider graphs rather than ancestry:

\begin{datalog}
  \atom{path}{X,Z} \gets \atom{edge}{X,Z}.
  \\
  \atom{path}{X,Z} \gets \atom{edge}{X,Y} \conj \atom{path}{Y,Z}.
\end{datalog}

\noindent
Suppose \name{edge} denotes a linear graph, $\{(1, 2),\, (2, 3),\, \dots,\,
({n-1}, n)\}$. Then \name{path} will denote reachability by a sequence of one or
more edges, $\setfor{(i, j)}{1 \le i < j \le n}$, or the transitive closure of
\name{edge}.
%
How can we compute this? The simplest approach is to begin with nothing
in the \name{path} relation and repeatedly apply its rules until nothing more is
deducible. We can make this strategy explicit by time-indexing the \name{path}
relation:

\begin{datalog}
  \name{path}_{i+1}(X,Z) \gets \atom{edge}{X,Z}.
  \\
  \name{path}_{i+1}(X,Z) \gets \atom{edge}{X,Y} \conj \name{path}_i(Y,Z).
\end{datalog}

\noindent
By omission $\name{path}_0 = \emptyset$.
%
From this inductively $\name{path}_i \subseteq \name{path}_{i+1}$, because at step $i+1$ we re-deduce every fact known at step $i$.
%
For example, suppose $\name{path}_i(j, k)$ holds. Then at step $i+1$ the second
rule deduces $\name{path}_{i+1}({j-1}, k)$ from
$\atom{edge}{{j-1}, j} \wedge \name{path}_i(j,k)$.
%
But since $\name{path}_{i+1}(j, k)$ holds, we perform the same deduction at time
$i+2$, and again at $i+3$, $i+4$, etc.

Because we append edges one at a time, $\name{path}_i$ contains all nonempty
paths of $i$ or fewer edges.
%
Therefore it takes $n$ steps until we reach our fixed point $\name{path}_{n-1} =
\name{path}_n$.
%
Since step $i$ involves $|\name{path}_i| \in \Theta(i^2)$ deductions, we make
$\Theta(n^3)$ deductions in total.
%
There being only $\Theta(n^2)$ paths in the final result, this is terribly
wasteful; hence we term this \emph{\naive\ evaluation}.

\label{section-seminaive-tc-in-datafun}

%% the least solution to the recursive equation:

%% \begin{code}
%% \name{path} = \name{edge} \cup
%% \setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in \name{path}}
%% \end{code}

%% \noindent
%% In other words, it is the

Now let's move from Datalog to Datafun.\footnote{In this section we do not
bother distinguishing monotone variables $\mvar x$ or discrete expressions
$\eiso e$, as it muddies our examples to no benefit.} The transitive closure of
\name{edge} is the least fixed point of the monotone function \name{step}
defined by:

%\begin{code}
\[
\name{step} \<s = \name{edge} \cup
\setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in s}
\]%\end{code}

\noindent
The \naive\ way to compute this is to simply iterate \name{step}, computing $\name{path}_i = \name{step}^i \<\emptyset$ inductively by letting:

\begin{align*}
  \name{path}_0 &= \emptyset
  &
  \name{path}_{i+1} &= \name{step} \<\name{path}_i
\end{align*}

\noindent
%% start from
%% \(\name{path}_0 = \emptyset\) and compute successive \(\name{path}_{i+1} =
%% \name{step}\<\name{path}_i\) until \(\name{path}_i = \name{path}_{i+1}\).
%% %
But as before, $\name{path}_i \subseteq \name{step}\<\name{path}_i$; each iteration re-computes the paths found by its predecessor.
%
We'd rather not compute the entire set, $\name{step} \< \name{path}_i$, but instead find a smaller subset of \emph{new} paths, let's call them $\name{dpath}_i$, such that $\name{path}_i \cup \name{dpath}_i = \name{step} \<\name{path}_i$.
%
The smallest such set is of course $\name{step}\<\name{path}_i \setminus \name{path}_i$, but we won't need this most-precise difference to prove our strategy correct, and the freedom to approximate can be useful for avoiding unnecessary work. \todolater{forward-reference implementation chapter where this becomes a problem}
%
Our iteration strategy then becomes:

\begin{align*}
  %% \name{path}_i &= \name{step}^i \<\emptyset
  %% &
  \name{path}_0 &= \emptyset
  &
  \name{path}_{i+1} &= \name{path}_i \cup \name{dpath}_i
  \\
  %% \name{path}_i \cup \name{dpath}_i &= \name{step}\<\name{path}_i
  %% &
  \name{dpath}_0 &= \textsf{\color{red}?} & \name{dpath}_{i+1} &= \textsf{\color{red}?}
\end{align*}

\noindent
The base case is easily solved by letting $\name{dpath}_0 = \name{step}\<\emptyset$. This wastes no work since there are no previously-known paths to be rediscovered. In the inductive case, we need to compute $\name{dpath}_{i+1}$ from $\name{path}_i$ and $\name{dpath}_i$. Let's imagine we have a function that does this, called $\name{step}'$:

\begin{align*}
  \name{path}_0 &= \emptyset
  &
  \name{path}_{i+1} &= \name{path}_i \cup \name{dpath}_i\\
  \name{dpath}_0 &= \name{step}\<\emptyset
  &
  \name{dpath}_{i+1} &= \name{step}' \<\name{path}_i \<\name{dpath}_i
\end{align*}

\noindent
If we wish to prove this iteration strategy correct, what must $\name{step}'$ do?
%
We wish to show inductively that $\name{step}\<\name{path}_i = \name{path}_{i+1}$.
%
The base case is trivial. So assuming $\name{step}\<\name{path}_{i} = \name{path}_{i+1}$, let's look at what we wish to prove and simplify it:

\begin{align*}
  \name{step} \<\name{path}_{i+1}
  &=
  \name{path}_{i+2}
  & \text{what we wish to show}
  \\
  \name{step} \<(\name{path}_i \cup \name{dpath}_i)
  &=
  \name{path}_{i+1} \cup \name{dpath}_{i+1}
  & \text{apply definitions}
  \\
  \name{step} \<(\name{path}_i \cup \name{dpath}_i)
  &=
  \name{step} \<\name{path}_i \cup \name{step}' \<\name{path}_i \<\name{dpath}_i
  & \text{apply IH and definitions}
\end{align*}

\noindent
So it suffices for $\name{step}'$ to have the following property:

\nopagebreak[1]
\[
\name{step}\<(s \cup \ds) = \name{step}\<s \cup \name{step}' \<s \<\ds 
\]

\noindent
Intuitively speaking, $\name{step}' \<s \<\ds$ captures how $\name{step}$'s output changes in response to changing input: as $s$ grows to $s \cup \ds$, how does $\name{step}\<s$ grow to $\name{step}\<(s \cup \ds)$?

The next question is: can we find a $\name{step}'$ with this property?
%
We can: for instance, \( \name{step}' \<s \<\ds = \name{step}\<(s
\cup \ds) \setminus \name{step}\<s \), or the even simpler $\name{step}' \<s \<\ds = \name{step}\<(s \cup \ds)$.
%
But these trivial solutions do not help us avoid wasteful computation: they repeatedly call \name{step} on ever-growing inputs, taking us back to \naive\ iteration.
%
So let's examine the behavior of $\name{step} \<(s \cup \ds)$ to see if we can find something more efficient:

\begin{align*}
  &\mathrel{\hphantom{=}} \name{step} \<(s \cup \ds)
  \\
  &= \name{edge} \cup \setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in s \cup \ds}
  \\
  &= {\colorA \name{edge} \cup \setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in s}} \cup {\colorB \setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in \ds}}
  \\
  &= {\colorA\name{step}\<s} \cup {\colorB \setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in \ds}}
\end{align*}

\noindent
Thus, a satisfactory definition of $\name{step}'$ is:

\begin{code}
\name{step}' \<s \<\ds = \setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in \ds}
\end{code}

%% \XXX
%% Instead, consider $\name{step}'$ defined by:

%% \begin{code}
%% \name{step}' \<s \<\ds = \setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in \ds}
%% \end{code}

%% \noindent
%% This has the desired property:
%% %

%% \begin{align*}
%%   &\mathrel{\hphantom{=}} \name{step} \<(s \cup \ds)
%%   \\
%%   &= \name{edge} \cup \setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in s \cup \ds}
%%   \\
%%   &= {\colorA \name{edge} \cup \setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in s}} \cup {\colorB \setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in \ds}}
%%   \\
%%   &= {\colorA\name{step}\<s} \cup {\colorB\name{step}' \<s \<\ds}
%% \end{align*}

%% \noindent
%% %% In other words, $\name{step}'$ tells us how \name{step} changes as its input
%% %% grows.
%% %
%% This lets us directly compute the changes $\name{dpath}_i$ between our
%% iterations $\name{path}_i$:

%% \begin{align*}
%%   \name{dpath}_0
%%   &= \name{step}\<\emptyset
%%   = \name{edge}
%%   \\
%%   \name{dpath}_{i+1}
%%   &= \name{step}'\<\name{dpath}_i
%%   = \setfor{(x,z)}{(x,y) \in \name{edge},\, (y,z) \in \name{dpath}_i}
%%   \\
%%   \name{path}_{i+1}
%%   &= \name{path}_i \cup \name{dpath}_i
%% \end{align*}

%% \noindent These exactly mirror the derivative and accumulator rules for
%% \(\name{path}_i\) and \(\name{dpath}_i\) we gave earlier. \fixme{jeremy}{produce a cross reference or page number here} \fixme{achim}{What did you give earlier and where?}

\noindent
The problem of semi\naive\ evaluation for Datafun reduces to \emph{automatically} finding functions, like $\name{step}'$, that compute the change in a function's output given a change to its input.
%
\todo{Say a bit more about how we need to generalize the above process to many types.}
%
This is a problem of \emph{incremental computation}, and since Datafun is a
functional language, we turn to the \emph{incremental
  \fn-calculus}~\citep{incremental,DBLP:conf/esop/GiarrussoRS19,DBLP:phd/dnb/Giarrusso20}.
